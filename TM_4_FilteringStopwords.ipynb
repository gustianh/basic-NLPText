{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TEXT MINING  4 - FILTERING AND STOPWORD REMOVAL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Date | April, 7th 2020\n",
    "--- | ---\n",
    "Male Tutor | Gustian Herlambang & Pahmi Alifya Bahri\n",
    "Female | Siti Rahmah & Imelda Putri Anggraini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pengertian**\n",
    "\n",
    "Filtering adalah proses menyaring kata atau memilah kata yang tidak berguna dalam suatu dokumen atau teks. Kata-kata itu dihapus atau dibuang karena dinilai tidak memiliki arti dalam proses `Text Mining`. Misalnya :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "contoh |\n",
    "--- |\n",
    "kuliah daring adalah bentuk dari usaha pemerintah untuk meredam COVID-19 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam proses filtering kita memerlukan `stopword` dimana stopword ini akan digunakan sebagai patokan kata mana saja yang harus dihilangkan dalam suatu kalimat atau dokumen. Misal kata yang perlu dihilangkan dalam suatu teks adalah kata penghubung 'di', 'ke', 'daripada', 'adalah', 'kepada', dsb. Kumpulan stopword ini juga sering di sebut dengan `wordlist`. Lalu bagaimana jika kalimat diatas jika di filter ? Kita akan membuang kata **adalah, dari, untuk**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "contoh |\n",
    "--- |\n",
    "kuliah daring  bentuk usaha pemerintah meredam COVID-19 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya kita akan mengimplementasikannya kedalam kodingan. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **A. Filtering dengan `NLTK`**\n",
    "\n",
    "Langkah awalnya kita import terlebih dahulu library `nltk`. Ketikkan kode berikut :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `import nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disini kita tetap harus melakukan `tokenizing` dan `case folding` agar kalimat kita memberikan akurasi yang baik. Untuk itu kita import fungsi `sent_tokenize` dan `word_tokenize` dari library `nltk`. Ketikkan kode berikut :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `from nltk.tokenize import sent_tokenize, word_tokenize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selanjutnya, kita import fungsi `stopword`. Ketikkan kode berikut :\n",
    "> `from nltk.corpus import stopwords`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita masih menggunakan kalimat yang sama seperti di modul pertemuan ke 2. Yaitu **\"Fakultas yang ada di Universitas Pakuan ada 6 diantaranya adalah Fakultas Teknik, MIPA, FISIB, FKIP, FH, dan Pasca-Sarjana\"**. Yang akan dideklarasikan dalam variable **teks**. Ketikkan kode berikut :\n",
    "> `teks = \"Fakultas yang ada di Universitas Pakuan ada 6 diantaranya adalah Fakultas Teknik, MIPA, FISIB, FKIP, FH, dan Pasca-Sarjana\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Disini kita akan menggunakan library `string` nah jangan lupa import library nya terlebiih dahulu.\n",
    "> `import string`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita lakukan proses case folding terlebih dahulu dengan kode berikut dan disimpan dalam variable **proses_cf**.\n",
    "> `proses_cf = teks.translate(str.maketrans('','', string.punctuation)).lower()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lalu kita lakukan tokenizing dan disimpan dalam variable **proses_token**. Ketikkan kode berikut :\n",
    "> `proses_token = nltk.tokenize.word_tokenize (proses_cf)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "proses melihat list stopword yang ada di nltk, lalu set bahasanya di bahasa Indonesia. Ketikkan kode berikut :\n",
    "> `listStopwords = set(stopwords.words('Indonesian'))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proses menghapus kata yaitu menggunakan argumen yang disimpan dalam variable **removed**. Lalu kita menggunakan perulangan `for`. Cara membacanya adalah *untuk t di variable proses_token, jika tidak ada teks didalam list stopword maka hapus dan gabungkan kembali*. Ketikkan kode berikut : ( **perhatikan indentasi** sperti contoh dibawah ini. Ingat Python itu `case sensitive` )\n",
    "\n",
    "> `removed = []`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">`for t in proses_token:`\n",
    "    >>> `if t not in listStopwords:`\n",
    "        >>>> `removed.append(t)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jika sudah, mari kita cetak hasilnya dengan mengetikkan kode berikut :\n",
    "    \n",
    "> `print(removed)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **B. Filtering dengan `Sastrawi`**\n",
    "\n",
    "Kita telah berhasil melakukan proses filtering dengan `nltk`. Kali ini kita akan menggunakan library `Sastrawi` khusus bahasa Indonesia. Tentunya `wordlist` nya akan lebih banyak dan telah disesuaikan. \n",
    "\n",
    "### **1. Melihat Daftar Wordlist** \n",
    "\n",
    "Nah, disini kita juga bisa menggunakan beberapa fungsi , misalnya kali ini kita akan menggunakan fungsi `StopWordRemover`. Ketikkan kode berikut untuk mengimport Sastrawi dan fungsinya : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita akan menampung fungsi tersebut dalam variable **factory**. Ketikkan kode berikut :\n",
    "> `factory = StopWordRemoverFactory()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lalu kita deklarasikan variable **daftar_stopword** untuk mendapatkan daftar stopword dari Sastrawi. Ketikkan kode berikut :\n",
    "\n",
    "> `daftar_stopword = factory.get_stop_words()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jika sudah kita tampilkan daftarnya. Ketikkan kode berikut ini :\n",
    "    \n",
    "> `print(daftar_stopword)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Filtering Dengan Sastrawi**\n",
    "\n",
    "Kita awali dengan import library dari Sastrawi. Ketikkan kode berikut : \n",
    "> `from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lakukan tokenizing menggunakan library `nltk`. Ketikkan kode berikut : ( **kita tidak perlu import library lagi karena sudah dilakukan diatas**)\n",
    ">`from nltk.tokenize import word_tokenize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita akan menampung fungsi tersebut dalam variable **factory**. Ketikkan kode berikut :\n",
    "> `factory = StopWordRemoverFactory()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mendeklarasikan variable **stopword** untuk menampung fungsi pembuatan `stopword_remover`. Ketikkan kode berikut :\n",
    "> `stopword = factory.create_stop_word_remover()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deklarasikan variable **kalimat** untuk menampung teks baru. Ketikkan kode berikut :\n",
    "    \n",
    "> `kalimat = \"Andi kerap melakukan transaksi rutin secara daring atau online. Menurut Andi belanja online lebih praktis & murah.\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lakukan proses case folding. Ketikkan kode berikut :\n",
    "> `kalimat_cf =kalimat.translate(str.maketrans('','',string.punctuation)).lower()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proses melakukan stopword dengan mendeklarasikan variable **kalimat_sw** \n",
    "> `kalimat_sw = stopword.remove(kalimat_cf)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jangan lupa lakukan tokenisasi. Ketikkan kode berikut :\n",
    "    \n",
    "> `kalimat_token = nltk.tokenize.word_tokenize(kalimat_sw)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cetak hasilnya. Ketik kode berikut :\n",
    "> `print(kalimat_token)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Menambah Stopword atau WordList sendiri\n",
    "\n",
    "Adalakanya dalam riset kita membutuhkan wordlist sendiri, karena didalam library yang bersangkutan tidak ada. Maka kita bisa mendeklarasikannya. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kodingannya masih sama dengan yang diatas namun ada beberapa penambahan yaitu variable **more_stopword** misalnya. Mari lihat pada kodingan dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory, StopWordRemover, ArrayDictionary\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_factory = StopWordRemoverFactory().get_stop_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deklarasikan variable **more_stopword** dan isilah wordlist apa yang mau ditambahkan. Disini saya mengisi dengan **daring dan online** Ketikkan kode berikut :\n",
    "    \n",
    "> `more_stopword = ['daring', 'online']`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kalimat = \"Andi kerap melakukan transaksi rutin secara daring atau online. Menurut Andi belanja online lebih praktis & murah.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gabungankan wordlist yang sudah dideklarasikan dengan variable **data**. Ketikkan kode berikut :\n",
    "> `data = stop_factory + more_stopword`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kode lanjutan\n",
    "dictionary = ArrayDictionary(data)\n",
    "str = StopWordRemover(dictionary)\n",
    "kalimat_sw = stopword.remove(kalimat)\n",
    "tokens = nltk.tokenize.word_tokenize(str.remove(kalimat_sw))\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- **Tetap Dirumah and Stay Safe** --"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
