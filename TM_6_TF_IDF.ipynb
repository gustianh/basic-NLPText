{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TEXT MINING 6 - TERM FREQUENCY & INVERSE DOCUMENT FREQUENCY**\n",
    "\n",
    "Build Date | April, 18th 2020\n",
    "--- | ---\n",
    "Male Tutor | Gustian Herlambang & Pahmi Alifya Bahri\n",
    "Female | Siti Rahmah & Imelda Putri Anggraini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **A. PROCESS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Import Library**\n",
    "\n",
    "Kali ini kita akan menggunakan 3 library yaitu :\n",
    "1. `RE`\n",
    "2. `Sastrawi`, dan \n",
    "3. `Scikit-Learn`\n",
    "\n",
    "Kemudian, untuk fungsi yang akan digunakan adalah : \n",
    "1. `CountVectorizer`, \n",
    "2. `TfidfVectorizer`, dan \n",
    "3. `StemmerFactory`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notes : konsep strukturisasi variable dalam Python termaktub dalam `8 PEP` , dicover more : https://www.python.org/dev/peps/pep-0008/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Open Text**\n",
    "\n",
    "Sebelum menjalankan semua kodingan dibawah ini pastikan bahwa kalian sudah melakukan scrap data text/document, yang disimpan dalam bentuk file `txt` dan sudah disimpan didalam `Jupyter Notebook`. Kali ini kita akan menggunakan 5 dokumen.\n",
    "\n",
    "Cara menyiapkan dokumen :\n",
    "1. Buka web browser\n",
    "2. Cari topik, misal tentang *internet*.\n",
    "3. Cari artikel apapun tentang internet, **copy** paragraf artikel dan **paste** di notepad.\n",
    "4. Save dalam bentuk `txt`.\n",
    "5. Upload semua txt kedalam Jupyter. \n",
    "6. Baru kerjakan coding code dibawah ini. \n",
    "\n",
    "Notes : U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_character = re.compile(r\"\\s\")\n",
    "def tokenize(text):\n",
    "    return [tokens.strip().lower() for tokens in clear_character.split(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"source1.txt\",\"r\");\n",
    "doc0 = file.read()\n",
    "\n",
    "file = open(\"source2.txt\",\"r\");\n",
    "doc1 = file.read()\n",
    "\n",
    "file = open(\"source3.txt\",\"r\");\n",
    "doc2 = file.read()\n",
    "\n",
    "file = open(\"source4.txt\",\"r\");\n",
    "doc3 = file.read()\n",
    "\n",
    "file = open(\"source5.txt\",\"r\");\n",
    "doc4 = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Case Folding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menghilangkan tanda baca\n",
    "tandabaca = [\".\",\",\",\"-\",\"%\",\"(\",\")\",\"?\"]\n",
    "for td in tandabaca:\n",
    "\tdoc0=doc0.replace(td,\"\")\n",
    "\tdoc1=doc1.replace(td,\"\")\n",
    "\tdoc2=doc2.replace(td,\"\")\n",
    "\tdoc3=doc3.replace(td,\"\")\n",
    "\tdoc4=doc4.replace(td,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menghilangkan angka\n",
    "docs0 = re.sub(r\"\\d+\", \" \", doc0)\n",
    "docs1 = re.sub(r\"\\d+\", \" \", doc1)\n",
    "docs2 = re.sub(r\"\\d+\", \" \", doc2)\n",
    "docs3 = re.sub(r\"\\d+\", \" \", doc3)\n",
    "docs4 = re.sub(r\"\\d+\", \" \", doc4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Stopwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords\n",
    "\n",
    "factory = StopWordRemoverFactory()\n",
    "stopword = factory.create_stop_word_remover()\n",
    "\n",
    "stopdocs0 = stopword.remove(docs0)\n",
    "stopdocs1 = stopword.remove(docs1)\n",
    "stopdocs2 = stopword.remove(docs2)\n",
    "stopdocs3 = stopword.remove(docs3)\n",
    "stopdocs4 = stopword.remove(docs4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming \n",
    "\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "stem1 = stemmer.stem(stopdocs0)\n",
    "stem2 = stemmer.stem(stopdocs1)\n",
    "stem3 = stemmer.stem(stopdocs2)\n",
    "stem4 = stemmer.stem(stopdocs3)\n",
    "stem5 = stemmer.stem(stopdocs4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Tokenisasi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "train_set = [stem1,stem2,stem3,stem4,stem5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(tokenizer=tokenize)\n",
    "data = count_vectorizer.fit_transform(train_set).toarray()\n",
    "vocab = count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. TF - IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Term of Frequency\n",
      "[[1 0 3 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 5 0 0]\n",
      " [0 3 0 ... 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Jumlah Term of Frequency\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vektor Features\n",
      "['accumulative', 'aceh', 'ada', 'adalah', 'adi', 'adu', 'ahp', 'aju', 'akan', 'akhir', 'akses', 'aksi', 'akurasi', 'alternatif', 'ambil', 'analisa', 'analytical', 'anggap', 'antara', 'apache', 'aparatur', 'atas', 'awal', 'badan', 'bagi', 'baik', 'bakat', 'balap', 'banding', 'bangun', 'bantu', 'banyak', 'bas', 'basis', 'bayes', 'beberapa', 'beda', 'belimbing', 'benar', 'beri', 'besar', 'biasa', 'bidang', 'bisa', 'bkd', 'blue', 'bobot', 'borda', 'buah', 'buka', 'bukti', 'burundi', 'butuh', 'calon', 'cctv', 'change', 'cipta', 'circuit', 'ciri', 'citra', 'closed', 'cocok', 'coratcoret', 'coretcoret', 'cropping', 'daerah', 'dalam', 'dan', 'dapat', 'dari', 'dasar', 'data', 'database', 'dekat', 'dengan', 'detection', 'deteksi', 'di', 'diamana', 'differences', 'dinding', 'dindingdinding', 'diri', 'dukung', 'dunia', 'e', 'efektif', 'efisien', 'egovernment', 'ekspektasi', 'ekstraksi', 'elektronik', 'end', 'fitur', 'front', 'fungsi', 'gabung', 'gam', 'gatewayhasil', 'gdss', 'gera', 'gerak', 'gihosha', 'government', 'green', 'guna', 'hadap', 'harap', 'hari', 'harus', 'hasil', 'hierarchy', 'hingga', 'ideal', 'identifikasi', 'ijin', 'illumination', 'images', 'industri', 'internet', 'invariant', 'isi', 'jabat', 'jadi', 'judi', 'jumlah', 'kabupaten', 'kamera', 'kandidat', 'kantor', 'kasus', 'kelahi', 'kelola', 'kelompok', 'keluh', 'kembang', 'kemudian', 'kerja', 'ketidaksesuaian', 'khusus', 'klasifikasi', 'kompetensi', 'kompetisi', 'komputer', 'komunikasi', 'kondisi', 'kota', 'kriteria', 'kualitas', 'kulit', 'kurang', 'laku', 'lalu', 'lapang', 'latih', 'layan', 'lebih', 'liar', 'lingkung', 'lowong', 'lulus', 'mahasiswa', 'maju', 'maksimal', 'maksimum', 'malam', 'mampu', 'manajemen', 'manis', 'manusia', 'masa', 'masalah', 'masih', 'masingmasing', 'masuk', 'masyarakat', 'mata', 'matching', 'maupun', 'mengganggap', 'metode', 'milik', 'model', 'modern', 'mysql', 'nai', 'nakal', 'negara', 'negaranegara', 'nepotisme', 'nilai', 'objektif', 'oleh', 'pada', 'pagi', 'panen', 'pasca', 'pegawai', 'pemrosesan', 'pengaruh', 'penting', 'perankingan', 'perintah', 'perlu', 'php', 'pilih', 'pkl', 'pns', 'politeknik', 'praktek', 'process', 'prodi', 'produksi', 'profil', 'profile', 'properti', 'proses', 'publik', 'putus', 'rangking', 'red', 'referensi', 'rekomendasi', 'remaja', 'rendah', 'republik', 'rgb', 'rupa', 'saat', 'saing', 'salah', 'sangat', 'satu', 'sebut', 'sedia', 'segi', 'selatan', 'semua', 'sepenuh', 'sering', 'server', 'sesuai', 'siang', 'siap', 'simpul', 'simulasi', 'sipil', 'sistem', 'skala', 'sms', 'solusi', 'sore', 'sortir', 'struktural', 'studi', 'suatu', 'subkriteria', 'sulit', 'swasta', 'tahu', 'tambah', 'tara', 'teknik', 'teknologi', 'television', 'teliti', 'tempat', 'tengahtengah', 'tentu', 'tepat', 'terap', 'tiap', 'tidak', 'tinggi', 'tingkat', 'tuju', 'tunjang', 'tunjuk', 'ubah', 'uji', 'undangundang', 'untuk', 'upa', 'upaya', 'usah', 'usaha', 'usul', 've', 'video', 'visual', 'waktu', 'warga', 'warna', 'web', 'webcam', 'yang']\n"
     ]
    }
   ],
   "source": [
    "print (\"Vektor Features\")\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer().fit_transform(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah TF - IDF\n",
      "  (0, 12)\t0.048398203571365365\n",
      "  (0, 273)\t0.04017488095286213\n",
      "  (0, 39)\t0.05998832584107542\n",
      "  (0, 7)\t0.05998832584107542\n",
      "  (0, 107)\t0.05998832584107542\n",
      "  (0, 164)\t0.05998832584107542\n",
      "  (0, 250)\t0.05998832584107542\n",
      "  (0, 241)\t0.05998832584107542\n",
      "  (0, 193)\t0.05998832584107542\n",
      "  (0, 36)\t0.05998832584107542\n",
      "  (0, 289)\t0.05998832584107542\n",
      "  (0, 144)\t0.05998832584107542\n",
      "  (0, 35)\t0.05998832584107542\n",
      "  (0, 278)\t0.04017488095286213\n",
      "  (0, 220)\t0.048398203571365365\n",
      "  (0, 28)\t0.05998832584107542\n",
      "  (0, 64)\t0.05998832584107542\n",
      "  (0, 259)\t0.05998832584107542\n",
      "  (0, 75)\t0.05998832584107542\n",
      "  (0, 55)\t0.05998832584107542\n",
      "  (0, 119)\t0.05998832584107542\n",
      "  (0, 115)\t0.05998832584107542\n",
      "  (0, 4)\t0.05998832584107542\n",
      "  (0, 116)\t0.05998832584107542\n",
      "  (0, 79)\t0.05998832584107542\n",
      "  :\t:\n",
      "  (4, 52)\t0.07117616412913944\n",
      "  (4, 165)\t0.03558808206456972\n",
      "  (4, 204)\t0.07117616412913944\n",
      "  (4, 221)\t0.07117616412913944\n",
      "  (4, 30)\t0.03558808206456972\n",
      "  (4, 14)\t0.10676424619370914\n",
      "  (4, 136)\t0.059082645833188785\n",
      "  (4, 202)\t0.03558808206456972\n",
      "  (4, 95)\t0.03558808206456972\n",
      "  (4, 217)\t0.249116574451988\n",
      "  (4, 83)\t0.10676424619370914\n",
      "  (4, 43)\t0.03558808206456972\n",
      "  (4, 232)\t0.03558808206456972\n",
      "  (4, 189)\t0.029541322916594392\n",
      "  (4, 261)\t0.03558808206456972\n",
      "  (4, 70)\t0.029541322916594392\n",
      "  (4, 170)\t0.059082645833188785\n",
      "  (4, 179)\t0.07455327641861204\n",
      "  (4, 104)\t0.06305668368322288\n",
      "  (4, 246)\t0.0994043685581494\n",
      "  (4, 134)\t0.029541322916594392\n",
      "  (4, 264)\t0.021018894561074294\n",
      "  (4, 109)\t0.0994043685581494\n",
      "  (4, 281)\t0.07117616412913944\n",
      "  (4, 68)\t0.0994043685581494\n"
     ]
    }
   ],
   "source": [
    "print (\"Jumlah TF - IDF\")\n",
    "print (tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc1 dan doc2 punya kemiripan sebesar: 1254.54%\n"
     ]
    }
   ],
   "source": [
    "# bandingkan doc1 dan doc5\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "doc1_vect = tfidf[0].reshape(1, -1) # doc1\n",
    "doc2_vect = tfidf[4].reshape(1, -1) # doc2\n",
    "\n",
    "# hitung jarak\n",
    "distance = manhattan_distances(doc1_vect, doc2_vect)\n",
    "print(\"doc1 dan doc2 punya kemiripan sebesar: {:.2%}\".format(distance.item(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **C. Kesimpulan**\n",
    "\n",
    "Dapat disimpulkan bahwa document 1 dengan document 5 mempunyai kemiripan sebesar **1254%**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
